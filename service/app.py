from fastapi import FastAPI
import pandas as pd
import pickle
import os
import json
from tensorflow.keras.models import model_from_json
import numpy as np
from pydantic import BaseModel
from typing import List

app = FastAPI(title="ML Prediction Service")

# Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model = None
scaler = None

# Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª
selected_features = [
    "nb_funding_rounds",
    "nb_investors", 
    "nb_offices",
    "ipo",
    "acquired",
    "milestones",
    "relationships",
    "funding_rounds"
]

# Ù†Ù…ÙˆØ°Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
class PredictionInput(BaseModel):
    nb_funding_rounds: float = 0
    nb_investors: float = 0
    nb_offices: float = 0
    ipo: float = 0
    acquired: float = 0
    milestones: float = 0
    relationships: float = 0
    funding_rounds: float = 0

# Ø¯Ø§Ù„Ø© Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
def load_ml_model():
    """ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ML ÙˆØ§Ù„Ù€ scaler"""
    global model, scaler
    
    try:
        print("ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
        
        # Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
        possible_paths = [
            # 1. Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ service Ø§Ù„Ø­Ø§Ù„ÙŠ
            {
                "arch": "mlp_model_architecture.json",
                "weights": "mlp_model.weights.h5", 
                "scaler": "mlp_model_scaler.pkl"
            },
            # 2. ÙÙŠ Ù…Ø¬Ù„Ø¯ Projects Ø¨Ø¬Ø§Ù†Ø¨ service
            {
                "arch": "../Projects/mlp_model_architecture.json",
                "weights": "../Projects/mlp_model.weights.h5",
                "scaler": "../Projects/mlp_model_scaler.pkl"
            },
            # 3. Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ Projects ÙÙŠ Ø§Ù„Ø­Ø§ÙˆÙŠØ©
            {
                "arch": "Projects/mlp_model_architecture.json",
                "weights": "Projects/mlp_model.weights.h5",
                "scaler": "Projects/mlp_model_scaler.pkl"
            }
        ]
        
        loaded = False
        for paths in possible_paths:
            arch_path = paths["arch"]
            weights_path = paths["weights"]
            scaler_path = paths["scaler"]
            
            if (os.path.exists(arch_path) and 
                os.path.exists(weights_path) and 
                os.path.exists(scaler_path)):
                
                print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ: {arch_path}")
                
                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                with open(arch_path, "r") as f:
                    model_json = f.read()
                model = model_from_json(model_json)
                model.load_weights(weights_path)
                
                # ØªØ­Ù…ÙŠÙ„ scaler
                with open(scaler_path, "rb") as f:
                    scaler = pickle.load(f)
                
                loaded = True
                print("ğŸ¯ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")
                break
        
        if not loaded:
            print("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ‡Ù…ÙŠ...")
            create_dummy_model()
            
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
        create_dummy_model()

def create_dummy_model():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ‡Ù…ÙŠ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    global model, scaler
    print("ğŸ”„ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ‡Ù…ÙŠ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±...")
    
    # Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ‡Ù…ÙŠ
    model = "dummy_model"
    
    # scaler ÙˆÙ‡Ù…ÙŠ
    import sklearn.preprocessing
    scaler = sklearn.preprocessing.StandardScaler()
    import numpy as np
    scaler.fit(np.random.rand(10, 8))
    
    print("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ‡Ù…ÙŠ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„
@app.on_event("startup")
def startup_event():
    print("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø®Ø¯Ù…Ø© ML...")
    load_ml_model()
    print(f"ğŸ“Š Ø§Ù„Ù…ÙŠØ²Ø§Øª: {selected_features}")

# Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
@app.get("/")
def home():
    return {
        "message": "ğŸ¯ ML Prediction Service",
        "status": "running",
        "model": "loaded" if model else "not_loaded",
        "features": selected_features,
        "endpoints": {
            "docs": "/docs",
            "health": "/health",
            "predict": "/predict (POST)",
            "test": "/test (GET)"
        }
    }

# ÙØ­Øµ Ø§Ù„ØµØ­Ø©
@app.get("/health")
def health():
    return {
        "status": "healthy",
        "model": "loaded" if model and model != "dummy_model" else "dummy",
        "service": "ml_prediction_api",
        "features_count": len(selected_features)
    }

# Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙ†Ø¨Ø¤
@app.post("/predict")
def predict(input_data: List[PredictionInput]):
    """
    Ø¥Ø¬Ø±Ø§Ø¡ ØªÙ†Ø¨Ø¤Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©
    """
    try:
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        data = [item.dict() for item in input_data]
        df = pd.DataFrame(data)
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª
        for feature in selected_features:
            if feature not in df.columns:
                df[feature] = 0
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ‡Ù…ÙŠ
        if model == "dummy_model":
            import numpy as np
            predictions = np.random.rand(len(df), 1).tolist()
            return {
                "status": "success",
                "model": "dummy",
                "predictions": predictions,
                "count": len(predictions)
            }
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
        X = df[selected_features]
        X_scaled = scaler.transform(X)
        predictions = model.predict(X_scaled).tolist()
        
        return {
            "status": "success",
            "predictions": predictions,
            "count": len(predictions),
            "features_used": selected_features
        }
        
    except Exception as e:
        return {
            "status": "error",
            "message": str(e),
            "error_type": type(e).__name__
        }

# Ù†Ù‚Ø·Ø© Ø§Ø®ØªØ¨Ø§Ø±
@app.get("/test")
def test_endpoint():
    """
    Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ‡Ù…ÙŠØ©
    """
    test_data = [
        PredictionInput(
            nb_funding_rounds=2.0,
            nb_investors=4.0,
            nb_offices=1.0,
            ipo=0.0,
            acquired=0.0,
            milestones=8.0,
            relationships=12.0,
            funding_rounds=2.0
        ),
        PredictionInput(
            nb_funding_rounds=5.0,
            nb_investors=8.0,
            nb_offices=3.0,
            ipo=1.0,
            acquired=0.0,
            milestones=15.0,
            relationships=20.0,
            funding_rounds=4.0
        )
    ]
    
    return predict(test_data)

# Ù†Ù‚Ø·Ø© Ù„Ø±Ø¤ÙŠØ© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
@app.get("/input_schema")
def input_schema():
    """Ø¹Ø±Ø¶ Ù‡ÙŠÙƒÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨"""
    return {
        "required_fields": selected_features,
        "example": {
            "nb_funding_rounds": 3.0,
            "nb_investors": 5.0,
            "nb_offices": 2.0,
            "ipo": 0.0,
            "acquired": 0.0,
            "milestones": 10.0,
            "relationships": 15.0,
            "funding_rounds": 3.0
        }
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)